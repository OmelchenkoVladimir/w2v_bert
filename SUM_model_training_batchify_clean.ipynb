{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "np.random.seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefinitionsDataset(Dataset): # train_maxlen = 103; set_to_128\n",
    "    \n",
    "    \n",
    "    def __init__(self, path_to_csv, tokenizer, max_len=128):\n",
    "        self.data = pd.read_csv(path_to_csv)\n",
    "        self.data['input'] = self.data['definition'].apply(lambda x: torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[CLS] [MASK] - ' + x + ' [SEP]'))))\n",
    "        self.data['embedding'] = self.data['embedding'].apply(lambda x: ast.literal_eval(x))\n",
    "        self.data['label'] = self.data['embedding'].apply(lambda x: torch.tensor(x))\n",
    "        self.data['input'] = self.data['input'].apply(lambda x: F.pad(input=x, pad=(0, max_len-(x.shape[0])), mode='constant', value=0))\n",
    "        self.data['attention'] = self.data['input'].apply(lambda x: torch.tensor([float(el>0) for el in x]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        return {'input': self.data.iloc[index]['input'], 'attention_mask':self.data.iloc[index]['attention'], 'label': self.data.iloc[index]['label']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DefinitionsDataset('rus/bert/bert_train.csv', tokenizer)\n",
    "valid = DefinitionsDataset('rus/bert/bert_valid.csv', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertToW2v(torch.nn.Module):\n",
    "    def __init__(self, bert_model_name, lin_shape_in, lin_shape_out, emb_layer): # -, 768, 100, 6\n",
    "        super(BertToW2v, self).__init__()\n",
    "        self.emb_layer = emb_layer\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\n",
    "        #self.bert_model.eval()\n",
    "        self.linear_model = torch.nn.Linear(lin_shape_in, lin_shape_out, bias=True) # bias?\n",
    "        torch.nn.init.uniform_(self.linear_model.weight, -0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input_sentence, mask): # ожидаем уже токенизированное предложение\n",
    "        _, _, encoded_layers = self.bert_model(input_sentence, attention_mask=mask)\n",
    "        bert_output = encoded_layers[self.emb_layer][:,1]\n",
    "        linear_output = self.linear_model(bert_output)\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw2v = BertToW2v('bert-base-multilingual-cased', lin_shape_in=768, lin_shape_out=500, emb_layer=6) # !\n",
    "bw2v.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(bw2v.parameters())\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = next(iter(train_dl))\n",
    "\n",
    "# bw2v(tmp['input'].to('cuda'), tmp['attention_mask'].to('cuda'))\n",
    "\n",
    "# tmp = bw2v.bert_model(tmp['input'].to('cuda'), attention_mask=tmp['attention_mask'].to('cuda'))\n",
    "\n",
    "# tmp[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING_LOSS: 0.07069383466397244; VALIDATION_LOSS: 0.03193657151029312\n",
      "TRAINING_LOSS: 0.03252904221895009; VALIDATION_LOSS: 0.030987392811809178\n",
      "TRAINING_LOSS: 0.030968375554902224; VALIDATION_LOSS: 0.030049145453334473\n",
      "TRAINING_LOSS: 0.03013421285098211; VALIDATION_LOSS: 0.029863462003272844\n",
      "TRAINING_LOSS: 0.029482792943053133; VALIDATION_LOSS: 0.02943343158959313\n",
      "TRAINING_LOSS: 0.028900750073117657; VALIDATION_LOSS: 0.029113666397327997\n",
      "TRAINING_LOSS: 0.028530679349105206; VALIDATION_LOSS: 0.028840845193398638\n",
      "TRAINING_LOSS: 0.028081303151442454; VALIDATION_LOSS: 0.0288057127237217\n",
      "TRAINING_LOSS: 0.027679554053111913; VALIDATION_LOSS: 0.028723401463042062\n",
      "TRAINING_LOSS: 0.02731770935737183; VALIDATION_LOSS: 0.028423616533941348\n",
      "TRAINING_LOSS: 0.026873421274111898; VALIDATION_LOSS: 0.028780802199697454\n",
      "TRAINING_LOSS: 0.026547554817226482; VALIDATION_LOSS: 0.028395618969938093\n",
      "TRAINING_LOSS: 0.02622205555948251; VALIDATION_LOSS: 0.028608240293329243\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    bw2v.train()\n",
    "    train_loss = 0.0\n",
    "    for dct in train_dl:\n",
    "        inputs = dct['input']\n",
    "        masks = dct['attention_mask']\n",
    "        labels = dct['label']\n",
    "        inputs = inputs.to('cuda')\n",
    "        masks = masks.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = bw2v(inputs, masks)\n",
    "        loss = loss_function(output, labels)\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('TRAINING_LOSS: ', end='')\n",
    "    print(train_loss / len(train_dl.dataset), end='')\n",
    "    \n",
    "    bw2v.eval()\n",
    "    valid_loss = 0.0\n",
    "    for dct in valid_dl:\n",
    "        inputs = dct['input']\n",
    "        masks = dct['attention_mask']\n",
    "        labels = dct['label']\n",
    "        inputs = inputs.to('cuda')\n",
    "        masks = masks.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = bw2v(inputs, masks)\n",
    "            loss = loss_function(output, labels)\n",
    "        \n",
    "        valid_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    print('; VALIDATION_LOSS: ', end='')\n",
    "    print(valid_loss / len(valid_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bw2v.state_dict(), f'models/batchify_ep13_l6.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
