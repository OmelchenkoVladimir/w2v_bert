{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "np.random.seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefinitionsDataset(Dataset): # train_maxlen = 103; set_to_128\n",
    "    \n",
    "    \n",
    "    def __init__(self, path_to_csv, tokenizer, max_len=128):\n",
    "        self.data = pd.read_csv(path_to_csv)\n",
    "        self.data['input'] = self.data['definition'].apply(lambda x: torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[CLS] [MASK] - ' + x + ' [SEP]'))))\n",
    "        self.data['embedding'] = self.data['embedding'].apply(lambda x: ast.literal_eval(x))\n",
    "        self.data['label'] = self.data['embedding'].apply(lambda x: torch.tensor(x))\n",
    "        self.data['input'] = self.data['input'].apply(lambda x: F.pad(input=x, pad=(0, max_len-(x.shape[0])), mode='constant', value=0))\n",
    "        self.data['attention'] = self.data['input'].apply(lambda x: torch.tensor([float(el>0) for el in x]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        return {'input': self.data.iloc[index]['input'], 'attention_mask':self.data.iloc[index]['attention'], 'label': self.data.iloc[index]['label']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DefinitionsDataset('rus/bert/bert_train.csv', tokenizer)\n",
    "valid = DefinitionsDataset('rus/bert/bert_valid.csv', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train.data[['word', 'definition', 'input', 'attention', 'embedding']].sample(10, random_state=1) # для ускорения; 30 считаются около 80 минут\n",
    "valid_sample = valid.data[['word', 'definition', 'input', 'attention', 'embedding']].sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertToW2v(torch.nn.Module):\n",
    "    def __init__(self, bert_model_name, lin_shape_in, lin_shape_out, emb_layer): # -, 768, 100, 6\n",
    "        super(BertToW2v, self).__init__()\n",
    "        self.emb_layer = emb_layer\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\n",
    "        #self.bert_model.eval()\n",
    "        self.linear_model = torch.nn.Linear(lin_shape_in, lin_shape_out, bias=True) # bias?\n",
    "        torch.nn.init.uniform_(self.linear_model.weight, -0.1, 0.1)\n",
    "        \n",
    "    def forward(self, input_sentence, mask): # ожидаем уже токенизированное предложение\n",
    "        _, _, encoded_layers = self.bert_model(input_sentence, attention_mask=mask)\n",
    "        bert_output = encoded_layers[self.emb_layer][:,1]\n",
    "        linear_output = self.linear_model(bert_output)\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw2v = BertToW2v('bert-base-multilingual-cased', lin_shape_in=768, lin_shape_out=500, emb_layer=6) # !\n",
    "bw2v.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(bw2v.parameters())\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = next(iter(train_dl))\n",
    "\n",
    "# bw2v(tmp['input'].to('cuda'), tmp['attention_mask'].to('cuda'))\n",
    "\n",
    "# tmp = bw2v.bert_model(tmp['input'].to('cuda'), attention_mask=tmp['attention_mask'].to('cuda'))\n",
    "\n",
    "# tmp[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING_LOSS: 0.11299442789890479; VALIDATION_LOSS: 0.02609861226096155\n",
      "<>\n",
      "TRAINING_LOSS: 0.029738251580962917; VALIDATION_LOSS: 0.025631878662936276\n",
      "<>\n",
      "TRAINING_LOSS: 0.027357553401870915; VALIDATION_LOSS: 0.025428610530274974\n",
      "<>\n",
      "TRAINING_LOSS: 0.02655836692874711; VALIDATION_LOSS: 0.025580886173978194\n",
      "<>\n",
      "TRAINING_LOSS: 0.02601480089637666; VALIDATION_LOSS: 0.024980647083253663\n",
      "<>\n",
      "TRAINING_LOSS: 0.025636628731260082; VALIDATION_LOSS: 0.025015462741583123\n",
      "<>\n",
      "TRAINING_LOSS: 0.02543819862560457; VALIDATION_LOSS: 0.024908868311029123\n",
      "<>\n",
      "TRAINING_LOSS: 0.025251290175444918; VALIDATION_LOSS: 0.024851020336139\n",
      "<>\n",
      "TRAINING_LOSS: 0.02507177707572325; VALIDATION_LOSS: 0.0247672165814481\n",
      "<>\n",
      "TRAINING_LOSS: 0.025003359461937356; VALIDATION_LOSS: 0.024801658601344746\n",
      "<>\n",
      "TRAINING_LOSS: 0.02483199575630772; VALIDATION_LOSS: 0.024789484260199127\n",
      "<>\n",
      "TRAINING_LOSS: 0.02482035364773646; VALIDATION_LOSS: 0.024548858517827885\n",
      "<>\n",
      "TRAINING_LOSS: 0.024708125479398022; VALIDATION_LOSS: 0.02463272560396943\n",
      "<>\n",
      "TRAINING_LOSS: 0.02464766332012046; VALIDATION_LOSS: 0.02457107099468772\n",
      "<>\n",
      "TRAINING_LOSS: 0.02464201736964698; VALIDATION_LOSS: 0.02462544410426603\n",
      "<>\n",
      "TRAINING_LOSS: 0.024597278702094036; VALIDATION_LOSS: 0.02460691892065296\n",
      "<>\n",
      "TRAINING_LOSS: 0.02454085812482267; VALIDATION_LOSS: 0.02456843955601445\n",
      "<>\n",
      "TRAINING_LOSS: 0.02453396769076683; VALIDATION_LOSS: 0.024595328683201814\n",
      "<>\n",
      "TRAINING_LOSS: 0.024498853359237946; VALIDATION_LOSS: 0.024653727447870206\n",
      "<>\n",
      "TRAINING_LOSS: 0.02441829546727847; VALIDATION_LOSS: 0.02457344104316877\n",
      "<>\n",
      "CPU times: user 13min 4s, sys: 3min 26s, total: 16min 31s\n",
      "Wall time: 16min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    bw2v.train()\n",
    "    train_loss = 0.0\n",
    "    for dct in train_dl:\n",
    "        inputs = dct['input']\n",
    "        masks = dct['attention_mask']\n",
    "        labels = dct['label']\n",
    "        inputs = inputs.to('cuda')\n",
    "        masks = masks.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = bw2v(inputs, masks)\n",
    "        loss = loss_function(output, labels)\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('TRAINING_LOSS: ', end='')\n",
    "    print(train_loss / len(train_dl.dataset), end='')\n",
    "    \n",
    "    bw2v.eval()\n",
    "    valid_loss = 0.0\n",
    "    for dct in valid_dl:\n",
    "        inputs = dct['input']\n",
    "        masks = dct['attention_mask']\n",
    "        labels = dct['label']\n",
    "        inputs = inputs.to('cuda')\n",
    "        masks = masks.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = bw2v(inputs, masks)\n",
    "            loss = loss_function(output, labels)\n",
    "        \n",
    "        valid_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    print('; VALIDATION_LOSS: ', end='')\n",
    "    print(valid_loss / len(valid_dl.dataset))\n",
    "    \n",
    "    writer.add_scalars('Loss', {'train_loss':(train_loss / len(train_dl.dataset)), 'valid_loss':(valid_loss / len(valid_dl.dataset))}, epoch+1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_sample[f'emb_epoch{epoch+1}'] = train_sample.apply(lambda row: list(bw2v(row['input'].unsqueeze(0).to('cuda'), row['attention'].unsqueeze(0).to('cuda')).cpu().numpy()[0]), axis=1)\n",
    "        print('<', end='')\n",
    "        valid_sample[f'emb_epoch{epoch+1}'] = valid_sample.apply(lambda row: list(bw2v(row['input'].unsqueeze(0).to('cuda'), row['attention'].unsqueeze(0).to('cuda')).cpu().numpy()[0]), axis=1)\n",
    "        print('>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bw2v.state_dict(), f'models/batchify_ep20_l6_5_15.mdl')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample.to_csv('rus/bert/train_sample.csv', index=None)\n",
    "valid_sample.to_csv('rus/bert/valid_sample.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
